{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2e23db-781c-4f70-bd68-b6e8daff0ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t\t<script type=\"text/javascript\">\n",
       "\t\t\t<!--\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('script');\n",
       "\t\t\t\telement.type = 'text/javascript';\n",
       "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('style');\n",
       "\t\t\t\telement.type = 'text/css';\n",
       "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('div');\n",
       "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
       "\t\t\t\tdocument.body.appendChild(element);\n",
       "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
       "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t-->\n",
       "\t\t\t</script>\n",
       "\t\t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ~/CPPN/utils.py\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1c2743e-5e08-4cc7-b9de-3fa9e79a8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PygLinkPropPredDataset(name='ogbl-ddi',\n",
    "                                 transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "adj_t = data.adj_t.to(device)\n",
    "adj = adj_t.to_dense()\n",
    "\n",
    "split_edge = dataset.get_edge_split()\n",
    "\n",
    "torch.manual_seed(12345)\n",
    "idx = torch.randperm(split_edge['train']['edge'].size(0))\n",
    "idx = idx[:split_edge['valid']['edge'].size(0)]\n",
    "split_edge['eval_train'] = {'edge': split_edge['train']['edge'][idx]}\n",
    "\n",
    "evaluator = Evaluator(name='ogbl-ddi')\n",
    "\n",
    "train_neg_edge = negative_sampling(split_edge['train']['edge'].T, num_nodes=adj.shape[0],\n",
    "                                 num_neg_samples=split_edge['train']['edge'].size(0), method='dense')\n",
    "\n",
    "split_edge['train']['edge_neg'] = train_neg_edge.T\n",
    "\n",
    "r = list(split_edge['train']['edge'][:, 0].detach().cpu().numpy()) + list(split_edge['train']['edge_neg'][:, 0].detach().cpu().numpy())\n",
    "c = list(split_edge['train']['edge'][:, 1].detach().cpu().numpy()) + list(split_edge['train']['edge_neg'][:, 1].detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53de200c-6203-4aba-b52f-1f3d4a4cb2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a5be0-4810-4c1d-8088-8063a5df854a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521cfe5c-e564-4acd-9941-4a6b61e3a9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3e6af13-bd6b-420e-9bb7-b58737afaea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention1D(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Attention1D, self).__init__()\n",
    "        self.attention_weights = nn.Parameter(torch.randn(input_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: Tensor of shape (batch_size, input_dim)\n",
    "        \n",
    "        Returns:\n",
    "        - output: Tensor of shape (batch_size, input_dim) after applying attention\n",
    "        \"\"\"\n",
    "        # Compute attention scores\n",
    "\n",
    "        x = x[:, :, :, None]\n",
    "        attn_scores = torch.matmul(x, self.attention_weights)\n",
    "        \n",
    "        # Apply softmax to attention scores\n",
    "        attn_scores = F.softmax(attn_scores, dim = -2).squeeze(-1)\n",
    "        \n",
    "        # Multiply input by attention scores\n",
    "\n",
    "        output = x.squeeze(-1) * attn_scores\n",
    "        \n",
    "        return output\n",
    "\n",
    "class CPPN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_feats, num_classes = None, num_layers = 2, num_hidden = 128, dropout = 0.1):\n",
    "        super(CPPN, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        self.in_feats = in_feats\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # self.attention =  Attention1D(input_dim = 1)\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(self.in_feats, self.num_hidden))\n",
    "        # self.class_layer_zero = torch.nn.Linear(self.num_hidden, self.num_hidden)\n",
    "        # self.class_layer = torch.nn.Linear(self.num_hidden, self.num_classes)\n",
    "        \n",
    "        for _ in range(self.num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(self.num_hidden, self.num_hidden))\n",
    "            \n",
    "        self.lins.append(torch.nn.Linear(self.num_hidden, 1))\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "            \n",
    "    def forward(self, x):\n",
    "\n",
    "        # x = self.attention(x)\n",
    "        \n",
    "        for idx, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            x = F.dropout(x, p = self.dropout, training = self.training)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        # c = self.class_layer_zero(x)\n",
    "        # c = self.class_layer(c)\n",
    "        \n",
    "        x = self.lins[-1](x)\n",
    "        \n",
    "        return x #torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a37a76bd-a355-4f25-8e53-32ba459dd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph(adj.detach().cpu().numpy())\n",
    "ig = igraph.Graph([[e[0], e[1]] for e in nx.to_edgelist(graph)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e074e60a-eedd-44a8-93d3-a86ff11890db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len_adj = np.zeros((adj.shape[0], adj.shape[1]))\n",
    "# for i in tqdm(range((adj.shape[0]))):\n",
    "#     for j in range(i, (adj.shape[0])):\n",
    "#         len_adj[i][j] = len_adj[j][i] = nx.shortest_path_length(graph, i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f29aa2e-e363-42c5-b340-c08741161fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shafi.z/CPPN/DGI/utils/process.py:211: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /opt/conda/conda-bld/pytorch_1716905979055/work/torch/csrc/utils/tensor_new.cpp:621.)\n",
      "  return torch.sparse.FloatTensor(indices, values, shape)\n",
      " 19%|█▉        | 471/2500 [00:13<00:59, 34.01it/s]\n"
     ]
    }
   ],
   "source": [
    "dgi = DGIEmbedding(graph = graph, \n",
    "           embed_dim = 64, \n",
    "           feature_matrix = None, \n",
    "           batch_size = 1, \n",
    "           patience = 25,\n",
    "           model_name = '_')\n",
    "\n",
    "dgi.embed()\n",
    "embed = dgi.get_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e28e6435-b4c5-4a63-ad3b-c83fdb2294c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fbabb4-c192-4161-ba99-fc1797b1f42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eb31bca-d440-4978-a25b-78996fb60f6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4267/4267 [00:13<00:00, 315.57it/s]\n"
     ]
    }
   ],
   "source": [
    "core_nodes = list(nx.k_core(graph).nodes)[:25] + list(np.random.choice(len(graph), 25))\n",
    "core_lengths = np.array([[nx.shortest_path_length(graph, i, n) for n in core_nodes] for i in tqdm(range(len(graph)))])\n",
    "norm_core_lengths = (core_lengths - np.min(core_lengths)) / np.ptp(core_lengths)\n",
    "\n",
    "a1 = adj @ adj\n",
    "a2 = a1 @ adj\n",
    "a3 = a2 @ adj\n",
    "a4 = a3 @ adj\n",
    "\n",
    "\n",
    "a1 = a1 - torch.diag(a1) * torch.eye(a1.shape[0], a1.shape[1]).to(device)\n",
    "a2 = a2 - torch.diag(a2) * torch.eye(a1.shape[0], a1.shape[1]).to(device)\n",
    "a3 = a3 - torch.diag(a3) * torch.eye(a1.shape[0], a1.shape[1]).to(device)\n",
    "a4 = a4 - torch.diag(a4) * torch.eye(a1.shape[0], a1.shape[1]).to(device)\n",
    "\n",
    "a1 = a1.detach().cpu().numpy()\n",
    "a2 = a2.detach().cpu().numpy()\n",
    "a3 = a3.detach().cpu().numpy()\n",
    "a4 = a4.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "hops = np.concatenate([a1, a2, a3, a4], axis = 0)\n",
    "hops = (hops - np.min(hops)) / np.ptp(hops)\n",
    "\n",
    "a1 = hops[:a1.shape[0], :]\n",
    "a2 = hops[a1.shape[0]:2*a1.shape[0], :]\n",
    "a3 = hops[2*a1.shape[0]:3*a1.shape[0], :]\n",
    "a4 = hops[3*a1.shape[0]:4*a1.shape[0], :]\n",
    "\n",
    "\n",
    "\n",
    "# Coordinates\n",
    "x_mat = np.tile((np.arange(adj.shape[0]) / adj.shape[0]), (adj.shape[0], 1)).T \n",
    "y_mat = np.tile((np.arange(adj.shape[1]) / adj.shape[1]), (adj.shape[1], 1)).T \n",
    "\n",
    "# Node Features\n",
    "np_feat = (embed @ embed.T)\n",
    "np_feat = (np_feat - np.min(np_feat)) / np.ptp(np_feat)\n",
    "\n",
    "# Hop Length \n",
    "# norm_len_adj = (len_adj - np.min(len_adj)) / np.ptp(len_adj)\n",
    "\n",
    "# Curvature\n",
    "deg = torch.sum(adj, axis = 1)\n",
    "curv = 4 - deg.unsqueeze(1) - deg.unsqueeze(0)\n",
    "curv = (curv - torch.min(curv)) / (torch.max(curv) - torch.min(curv))\n",
    "curv = curv.detach().cpu().numpy()\n",
    "\n",
    "# Input Matrix\n",
    "in_mat = np.stack([x_mat, y_mat, np_feat, curv, a1, a2, a3, a4], -1)\n",
    "\n",
    "# Structural Features \n",
    "# sense_feat_dict, sense_features = get_sense_features(graph)\n",
    "# feat_map = np.zeros((sense_features.shape[0], sense_features.shape[0], 2 * sense_features.shape[1]))\n",
    "# for i in range(sense_features.shape[0]):\n",
    "#     for j in range(sense_features.shape[0]):\n",
    "#         feat_map[i, j, :] = np.concatenate([sense_features[i], sense_features[j]])\n",
    "\n",
    "# Lengths to Core Nodes\n",
    "core_map = np.zeros((norm_core_lengths.shape[0], norm_core_lengths.shape[0], 2 * norm_core_lengths.shape[1]))\n",
    "for i in range(norm_core_lengths.shape[0]):\n",
    "    for j in range(norm_core_lengths.shape[0]):\n",
    "        core_map[i, j, :] = np.concatenate([norm_core_lengths[i], norm_core_lengths[j]])\n",
    "\n",
    "in_mat = np.concatenate([in_mat, core_map], axis = -1)\n",
    "\n",
    "in_mat = torch.Tensor(in_mat)\n",
    "in_mat = in_mat.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "78f1a91a-2a90-4fb5-80f3-6c0b4b61e760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770002"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_feats = 7 + core_map.shape[-1] #+ feat_map.shape[-1]\n",
    "\n",
    "cppn = CPPN(in_feats = in_mat.shape[-1], #+ context.shape[0],\n",
    "            num_layers = 2,\n",
    "            num_classes = 0,\n",
    "            num_hidden = 7000,\n",
    "            dropout = 0.5).to(device)\n",
    "\n",
    "optimizer = optim.Adam(cppn.parameters(),\n",
    "                       lr = 5e-4,\n",
    "                       weight_decay = 1e-6)\n",
    "sum(p.numel() for p in cppn.parameters() if p.requires_grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e611628-b065-4110-b0f9-351d01a5afa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c843cc-1024-4a80-bbb7-1805b32391b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e048958-9efe-49e2-95fc-2779d50466d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "75f42a3b-ae79-4b75-ab34-4800c4e6853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = torch.nn.Transformer(d_model = 1, nhead = 1, dim_feedforward = 2048, num_encoder_layers = 6, num_decoder_layers = 6).to(device)\n",
    "\n",
    "# optimizer = optim.Adam(t.parameters(),\n",
    "#                        lr = 5e-4,\n",
    "#                        weight_decay = 1e-6)\n",
    "\n",
    "# sum(p.numel() for p in t.parameters() if p.requires_grad) \n",
    "\n",
    "# t.train()\n",
    "# batch_size = 512\n",
    "# batch_splits = list(np.arange(0, in_mat.shape[0] * in_mat.shape[1], batch_size))\n",
    "# if in_mat.shape[0] * in_mat.shape[1] not in batch_splits:\n",
    "#     batch_splits.append(adj.shape[0])\n",
    "\n",
    "# src = in_mat.reshape(in_mat.shape[-1], -1, 1).to(device)\n",
    "# tgt = adj.reshape(1, -1, 1).to(device)\n",
    "\n",
    "# mask = np.zeros(adj.shape)\n",
    "# mask[r, c] = 1\n",
    "# mask = torch.Tensor(mask).to(device)\n",
    "# mask = mask.reshape(1, -1, 1)\n",
    "\n",
    "# for e in range(1):\n",
    "#     epoch_loss = []\n",
    "#     for idx in tqdm(range(len(batch_splits) - 1)):\n",
    "    \n",
    "#         optimizer.zero_grad()\n",
    "#         batch_src = src[:, batch_splits[idx]:batch_splits[idx + 1]]\n",
    "#         batch_tgt = tgt[:, batch_splits[idx]:batch_splits[idx + 1]]\n",
    "#         batch_mask = mask[:, batch_splits[idx]:batch_splits[idx + 1]]\n",
    "        \n",
    "#         out = t(batch_src, batch_tgt)\n",
    "#         diff = (out - batch_tgt) * batch_mask\n",
    "#         batch_loss = torch.sum(torch.square(diff)) \n",
    "#         batch_loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss.append(batch_loss.item())\n",
    "            \n",
    "#     print (\"Epoch : \", e, \"Loss : \", np.sum(epoch_loss), end = '\\r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04675bd-3436-4db3-9f82-4526f3d61f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abae6a0-576b-471e-8579-cd3a656beb86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7141d2d0-9258-4327-b5d2-44e0c72e1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(adj.shape)\n",
    "mask[r, c] = 1\n",
    "mask = torch.Tensor(mask).to(device)\n",
    "batch_size = 256\n",
    "batch_splits = list(np.arange(0, in_mat.shape[0], batch_size))\n",
    "if adj.shape[0] not in batch_splits:\n",
    "    batch_splits.append(adj.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "94cbca16-0664-46ef-bf34-3ca5afb94574",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_mask = adj.detach().cpu().numpy().copy()\n",
    "weight_mask[weight_mask == 0] = 1e-1\n",
    "weight_mask = torch.Tensor(weight_mask).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192dcabd-ee32-4972-a9f3-83d6a1e7ecd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a92f319f-76aa-43f8-b10d-d64516694458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  249 Loss :  6612.7430982589725\r"
     ]
    }
   ],
   "source": [
    "cppn.train()\n",
    "for e in range(250):\n",
    "\n",
    "    epoch_loss = []\n",
    "    for r_idx in range(len(batch_splits) - 1):\n",
    "\n",
    "        for c_idx in range(len(batch_splits) - 1):\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch_in = in_mat[batch_splits[r_idx]:batch_splits[r_idx + 1],\n",
    "                              batch_splits[c_idx]:batch_splits[c_idx + 1],\n",
    "                              :]\n",
    "            batch_adj = adj[batch_splits[r_idx]:batch_splits[r_idx + 1], batch_splits[c_idx]:batch_splits[c_idx + 1]]\n",
    "            batch_mask = mask[batch_splits[r_idx]:batch_splits[r_idx + 1], batch_splits[c_idx]:batch_splits[c_idx + 1]]\n",
    "            batch_weight_mask = weight_mask[batch_splits[r_idx]:batch_splits[r_idx + 1], batch_splits[c_idx]:batch_splits[c_idx + 1]]\n",
    "    \n",
    "            batch_out = cppn(batch_in)\n",
    "            batch_out = batch_out.reshape(batch_in.shape[0], batch_in.shape[1])\n",
    "            \n",
    "            diff = (batch_out - batch_adj) * batch_mask * batch_weight_mask\n",
    "            batch_loss = torch.sum(torch.square(diff)) \n",
    "        \n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(batch_loss.item())\n",
    "        \n",
    "    print (\"Epoch : \", e, \"Loss : \", np.sum(epoch_loss), end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e8258-016f-46df-9fac-4e68ae2c3432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8c69612-3ac4-43d2-b4e7-c10b8d71c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cppn.state_dict(), './cppn_lp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "30d376bd-2185-47e7-916a-b5432049ef0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.71 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(batch_splits) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      9\u001b[0m     batch_in \u001b[38;5;241m=\u001b[39m in_mat[batch_splits[r_idx]:batch_splits[r_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     10\u001b[0m                       batch_splits[c_idx]:batch_splits[c_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     11\u001b[0m                       :]\n\u001b[0;32m---> 12\u001b[0m     batch_out \u001b[38;5;241m=\u001b[39m \u001b[43mcppn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     batch_out \u001b[38;5;241m=\u001b[39m batch_out\u001b[38;5;241m.\u001b[39mreshape(batch_in\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], batch_in\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     15\u001b[0m     recon_adj[batch_splits[r_idx]:batch_splits[r_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], batch_splits[c_idx]:batch_splits[c_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m batch_out\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/mambaforge/envs/mgpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/mgpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[26], line 59\u001b[0m, in \u001b[0;36mCPPN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# x = self.attention(x)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, lin \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlins[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m---> 59\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m     61\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/mambaforge/envs/mgpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/mgpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/mgpu/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.71 GiB. GPU "
     ]
    }
   ],
   "source": [
    "# cppn.load_state_dict(torch.load('./cppn_lp.pkl'))\n",
    "\n",
    "recon_adj = np.zeros(adj.shape)\n",
    "\n",
    "for r_idx in tqdm(range(len(batch_splits) - 1)):\n",
    "\n",
    "    for c_idx in range(len(batch_splits) - 1):\n",
    "        \n",
    "        batch_in = in_mat[batch_splits[r_idx]:batch_splits[r_idx + 1],\n",
    "                          batch_splits[c_idx]:batch_splits[c_idx + 1],\n",
    "                          :]\n",
    "        batch_out = cppn(batch_in)\n",
    "        batch_out = batch_out.reshape(batch_in.shape[0], batch_in.shape[1])\n",
    "    \n",
    "        recon_adj[batch_splits[r_idx]:batch_splits[r_idx + 1], batch_splits[c_idx]:batch_splits[c_idx + 1]] = batch_out.detach().cpu().numpy()\n",
    "recon_adj = (recon_adj + recon_adj.T) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a1538-4425-4ac1-800c-69ad805f29a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99ba51-70a3-4ad9-851a-b1bd0ea658e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0173269e-4a4c-425b-bc25-7047b3a2f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_adj = torch.Tensor(recon_adj).to(device)\n",
    "deg = torch.sum(adj, axis = 1)\n",
    "curv = 4 - deg.unsqueeze(1) - deg.unsqueeze(0)\n",
    "\n",
    "best_diff = np.inf\n",
    "best_t = None\n",
    "for t in np.arange(100) / 100: \n",
    "    recon_deg = torch.sum(recon_adj > t, axis = 1)\n",
    "    recon_curv = 4 - recon_deg.unsqueeze(1) - recon_deg.unsqueeze(0)\n",
    "    c_diff = torch.sum(torch.abs(recon_curv - curv))\n",
    "    if c_diff < best_diff: \n",
    "        best_diff = c_diff\n",
    "        best_t = t\n",
    "\n",
    "recon_deg = torch.sum(recon_adj > best_t, axis = 1)\n",
    "recon_curv = 4 - recon_deg.unsqueeze(1) - recon_deg.unsqueeze(0)\n",
    "\n",
    "plt.hist(recon_curv.detach().cpu().numpy().flatten(), bins = 100)\n",
    "plt.hist(curv.detach().cpu().numpy().flatten(), bins = 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f0e8f-b75f-4765-9f0c-b6802c5d97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(recon_adj.detach().cpu().numpy() > best_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d64c0-7325-4ab4-91d3-be2df192bd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35aef7f-5387-4f40-b90f-6ad64225893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [recon_adj[a,b].item() for a, b in split_edge['test']['edge'].detach().cpu().numpy()]\n",
    "n = [recon_adj[a,b].item() for a, b in split_edge['test']['edge_neg'].detach().cpu().numpy()]\n",
    "preds = p + n\n",
    "print (\"AUC : \", roc_auc_score([1 for _ in range(len(p))] + [0 for _ in range(len(n))], preds))\n",
    "results = {}\n",
    "k = 20\n",
    "evaluator.K = k\n",
    "test_hits = evaluator.eval({\n",
    "            'y_pred_pos': np.array(p),\n",
    "            'y_pred_neg': np.array(n),\n",
    "        })[f'hits@' + str(k)]\n",
    "print (\"Hits@\" + str(k) + \" : \", test_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80c792-4642-409b-a6ca-39b5a9fb3cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ef3c7-c68d-4c9c-a390-fd98ce6e17bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  635 Loss :  152862.51385498047\r"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(cppn.parameters(),\n",
    "                       lr = 5e-4,\n",
    "                       weight_decay = 1e-4)\n",
    "\n",
    "cppn.train()\n",
    "for e in range(1000):\n",
    "\n",
    "    epoch_loss = []\n",
    "    for r_idx in range(len(batch_splits) - 1):\n",
    "\n",
    "        for c_idx in range(len(batch_splits) - 1):\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch_in = in_mat[batch_splits[r_idx]:batch_splits[r_idx + 1],\n",
    "                              batch_splits[c_idx]:batch_splits[c_idx + 1],\n",
    "                              :]\n",
    "            batch_adj = adj[batch_splits[r_idx]:batch_splits[r_idx + 1], batch_splits[c_idx]:batch_splits[c_idx + 1]]\n",
    "            batch_mask = mask[batch_splits[r_idx]:batch_splits[r_idx + 1], batch_splits[c_idx]:batch_splits[c_idx + 1]]\n",
    "    \n",
    "            batch_out = cppn(batch_in)\n",
    "            batch_out = batch_out.reshape(batch_in.shape[0], batch_in.shape[1])\n",
    "            \n",
    "            diff = (batch_out - batch_adj) * batch_mask\n",
    "            batch_loss = torch.sum(torch.square(diff)) \n",
    "        \n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss.append(batch_loss.item())\n",
    "        \n",
    "    print (\"Epoch : \", e, \"Loss : \", np.sum(epoch_loss), end = '\\r')#, \"Curvature Loss : \", curv_loss.item(), \")\", end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53554c2b-534c-43cd-ba93-bc2dc5672d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152183.36853790283"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c0f6de-df61-49cf-8699-f3c2a9f5f9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
